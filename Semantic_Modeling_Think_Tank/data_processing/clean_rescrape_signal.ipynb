{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import requests \n",
    "import bs4 \n",
    "import nltk.data\n",
    "from datetime import datetime\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('daily_signal_full_text.csv')\n",
    "data['text'] = data['text'].apply(lambda x: x.strip() if isinstance(x, str) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['text']!=0] ## excluding graphics\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sent'] = data['text'].apply(lambda x: [j for i in x.split('\\n') \n",
    "                                             for j in tokenizer.tokenize(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = data['Sent'].sum()\n",
    "count = Counter(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_words = ['Photo', 'java', 'â€¦', '***', 'http', 'if(', 'for(',\n",
    "              'Photo credit:', 'Morning Bell', 'Read more', 'Originally appeared',\n",
    "              'For more information', 'podcast', 'leave a review',\n",
    "              'leave us a message', 'COPYRIGHT', 'DISTRIBUTED', 'Originally published',\n",
    "              'email protected', 'LEARN MORE', 'Quick Hits', 'Newscom', 'Click here',\n",
    "              'We also cover these stories', 'Opportunity Scholarship Program',\n",
    "              'This article has been modified', '[CDATA[', 'General_URL', 'Read More']\n",
    "drop_sent = []\n",
    "for i in count:\n",
    "    if len(i.split('\\\\')) > 2: drop_sent.append(i)\n",
    "    if len(i.split('/')) > 2: drop_sent.append(i)\n",
    "    if len(i.split('='))  > 2: drop_sent.append(i)\n",
    "    if len(i.split('\\t')) > 2: drop_sent.append(i)\n",
    "    if len(i.split('}'))  > 2: drop_sent.append(i)\n",
    "    for j in drop_words:\n",
    "        if j in i: \n",
    "            drop_sent.append(i)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_sent'] = data['Sent'].apply(lambda x: \n",
    "                                          [i for i in x if i not in drop_sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['cleaned_sent'].apply(lambda x: \"\\n\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['urls', 'category', 'date', 'text', 'authors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('signal_cleaned_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
