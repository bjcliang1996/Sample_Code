{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import bs4 \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Target Links\n",
    "The Hoover Institution website redirects all requests that specify a page number. Therefore I manually downloaded all pages from https://www.hoover.org/publications/policy-review to extract urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = 'draft_data/policy_review/'\n",
    "links = []\n",
    "for i in range(1, 99):\n",
    "    file = fpath + f\"{i}.htm\"\n",
    "    soup = bs4.BeautifulSoup(open(file).read()).body.findAll('a')\n",
    "    href = list(set([i.get('href') for i in soup]))\n",
    "    links.extend([i for i in href if i and \"/research/\" in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_count = Counter(links)\n",
    "links = list(set([i for i in link_count if link_count[i] < 5]))\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.exceptions import MissingSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880\r"
     ]
    }
   ],
   "source": [
    "soup_dict = dict()\n",
    "wrong_url = []\n",
    "start = 0\n",
    "\n",
    "for ind, url in enumerate(links):\n",
    "    if ind < start: continue ## rerun when interrupted\n",
    "    if ind % 10 == 0: print(ind, end = '\\r')\n",
    "    #if (ind % 5000 == 0) and (ind != start): break ## save every 10000 pages\n",
    "    try: r = requests.get(url.split('?')[0])\n",
    "    except MissingSchema:\n",
    "        wrong_url.append(url)\n",
    "        continue\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    soup_dict[ind] = soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for ind in soup_dict:\n",
    "    t = soup_dict[ind].body.findAll('p')\n",
    "    t = [i.text for i in t]\n",
    "    txt = []\n",
    "    for i in t:\n",
    "        if i == 'View the discussion thread.': break\n",
    "        if len(i) == 0: continue\n",
    "        if i == 'Donate now': txt = []\n",
    "        else: txt.append(i)\n",
    "    txt = \"\\n\".join(txt)\n",
    "    text.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "for ind in soup_dict:\n",
    "    \n",
    "    try: t = soup_dict[ind].body.findAll('div', {'class': \n",
    "                                                 'field-name-field-research-authors'})[0]\n",
    "    except IndexError: \n",
    "        authors.append('')\n",
    "        continue\n",
    "    t = set([i.text for i in t])\n",
    "    t.remove('by ')\n",
    "    authors.append('; '.join(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "for ind in soup_dict:\n",
    "    t = soup_dict[ind].body.findAll('span', {'class': 'date-display-single'})[0].text\n",
    "    date.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.hoover.org/research/sending-public...</td>\n",
       "      <td>The untold story of special education\\nOne of ...</td>\n",
       "      <td>Jonathan Fox</td>\n",
       "      <td>Friday, January 1, 1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.hoover.org/research/uns-waste-frau...</td>\n",
       "      <td>In 1992 and 1993, former U.S. Attorney General...</td>\n",
       "      <td>Adam Meyerson</td>\n",
       "      <td>Saturday, April 1, 1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.hoover.org/research/state-special-...</td>\n",
       "      <td>The former u.s. ambassador to the Court of St....</td>\n",
       "      <td>Robin Harris</td>\n",
       "      <td>Saturday, June 1, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.hoover.org/research/civic-renewal-...</td>\n",
       "      <td>In two recent reports, elite opinion is divide...</td>\n",
       "      <td>Don Eberly</td>\n",
       "      <td>Tuesday, September 1, 1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.hoover.org/research/oblivious-voter</td>\n",
       "      <td>Thomas E. Patterson.The Vanishing Voter: Publi...</td>\n",
       "      <td>Benjamin Wallace-Wells</td>\n",
       "      <td>Tuesday, April 1, 2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.hoover.org/research/sending-public...   \n",
       "1  https://www.hoover.org/research/uns-waste-frau...   \n",
       "2  https://www.hoover.org/research/state-special-...   \n",
       "3  https://www.hoover.org/research/civic-renewal-...   \n",
       "4    https://www.hoover.org/research/oblivious-voter   \n",
       "\n",
       "                                                text                  author  \\\n",
       "0  The untold story of special education\\nOne of ...            Jonathan Fox   \n",
       "1  In 1992 and 1993, former U.S. Attorney General...           Adam Meyerson   \n",
       "2  The former u.s. ambassador to the Court of St....            Robin Harris   \n",
       "3  In two recent reports, elite opinion is divide...              Don Eberly   \n",
       "4  Thomas E. Patterson.The Vanishing Voter: Publi...  Benjamin Wallace-Wells   \n",
       "\n",
       "                         date  \n",
       "0     Friday, January 1, 1999  \n",
       "1     Saturday, April 1, 1995  \n",
       "2      Saturday, June 1, 2002  \n",
       "3  Tuesday, September 1, 1998  \n",
       "4      Tuesday, April 1, 2003  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'url': links, 'text': text, 'author': authors, 'date': date})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('policy_review_total_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
