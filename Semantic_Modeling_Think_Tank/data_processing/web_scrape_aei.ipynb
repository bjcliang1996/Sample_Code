{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import bs4 \n",
    "import pandas as pd\n",
    "import re\n",
    "#import urllib\n",
    "from requests.exceptions import MissingSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextFromPage(soup):\n",
    "    if not soup: return \"\"\n",
    "    lst = [i.text.strip('\\n') for i in soup.findAll(\"p\", {\"class\" : None})]\n",
    "    lst = [i.replace('\\n', ' ') for i in lst if len(i)>1]\n",
    "    if len(lst) == 0: return \"\"\n",
    "    if lst[-1] == 'Tags:': lst = lst[:-1]\n",
    "    return '\\n'.join(lst)\n",
    "\n",
    "def getNameFromPage(soup):\n",
    "    lst = soup.findAll(\"div\", {\"class\" : 'post-author'})\n",
    "    lst = [i.text.split('\\n')[2] for i in lst]\n",
    "    authors = [i for i in lst if len(i) != 0]\n",
    "    if len(authors) != 0: return authors\n",
    "    lst = soup.findAll(\"em\")\n",
    "    lst = [i.text for i in lst]\n",
    "    lst = [i[:i.index(' is')] for i in lst if \" is\" in i]\n",
    "    return lst\n",
    "\n",
    "def getDateFromPage(soup):\n",
    "    lst = soup.findAll(\"div\", {\"class\" : 'post-date'})\n",
    "    lst = [i.text for i in lst]\n",
    "    return lst\n",
    "\n",
    "def getTagFromPage(soup):\n",
    "    tags = soup.findAll(\"meta\",  property=\"article:tag\")\n",
    "    tags = [i['content'] for i in tags]\n",
    "    return tags\n",
    "\n",
    "def getSectionFromPage(soup):\n",
    "    section = soup.findAll(\"meta\",  property=\"article:section\")\n",
    "    section = [i['content'] for i in section]\n",
    "    return section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Target Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soups(url):\n",
    "    r = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(r.text, \"html.parser\").body\n",
    "    if not soup: \n",
    "        print(url)\n",
    "        return []\n",
    "    return soup.findAll('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4580\r"
     ]
    }
   ],
   "source": [
    "max_page = 4582 ## from https://www.aei.org/search-results\n",
    "soups = []\n",
    "for i in range(1, max_page): \n",
    "    if i % 10 == 0: print(i, end = '\\r')\n",
    "    url = f'https://www.aei.org/search-results/?wpsolr_page={i}'\n",
    "    soups.extend(get_soups(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "href = set([i.get('href') for i in soups])\n",
    "href = [i for i in href if i and \"www.aei.org\" in i]\n",
    "cleaned_href = []\n",
    "for i in href:\n",
    "    not_wanted = [\"/search-results/\", \"/multimedia/\", \n",
    "                  \"/events/\", \"/profile/\", \"/publishers/\"]\n",
    "    pass_it = False\n",
    "    for j in not_wanted:\n",
    "        if j in i: pass_it = True \n",
    "    if not pass_it: cleaned_href.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.DataFrame({'urls': cleaned_href})\n",
    "#data.to_csv('url_aei.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Pages from Urls, Get Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77521"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('url_aei.csv')\n",
    "cleaned_href = list(data['urls'])\n",
    "len(cleaned_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77520\r"
     ]
    }
   ],
   "source": [
    "#soup_dict = dict()\n",
    "#wrong_url = []\n",
    "start = 75780\n",
    "\n",
    "for ind, url in enumerate(cleaned_href):\n",
    "    if ind < start: continue ## rerun when interrupted\n",
    "    if ind % 10 == 0: print(ind, end = '\\r')\n",
    "    if (ind % 10000 == 0) and (ind != start): break ## save every 10000 pages\n",
    "    try: r = requests.get(url.split('?')[0])\n",
    "    except MissingSchema:\n",
    "        wrong_url.append(url)\n",
    "        continue\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    soup_dict[ind] = soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Information from Soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls, texts, authors, date, tag, section = [],[],[],[],[],[]\n",
    "for i in soup_dict:\n",
    "    urls.append(cleaned_href[i])\n",
    "    texts.append(getTextFromPage(soup_dict[i]))\n",
    "    authors.append(getNameFromPage(soup_dict[i]))\n",
    "    date.append(getDateFromPage(soup_dict[i]))\n",
    "    tag.append(getTagFromPage(soup_dict[i]))\n",
    "    section.append(getSectionFromPage(soup_dict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'url':urls, 'text': texts, 'author': authors, \"date\": date,\n",
    "                     'tag': tag, \"section\": section})\n",
    "data['len'] = data['date'].apply(lambda x: len(x))\n",
    "data = data[data['text'] != \"\"]\n",
    "data = data[data['len'] != 0]\n",
    "data['date'] = data['date'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6812, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>tag</th>\n",
       "      <th>section</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.aei.org/carpe-diem/map-of-the-gove...</td>\n",
       "      <td>The map above from the Freedom Center of Misso...</td>\n",
       "      <td>[Mark J. Perry]</td>\n",
       "      <td>August 6, 2011</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Carpe Diem]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.aei.org/carpe-diem/from-45-to-15-i...</td>\n",
       "      <td>Ten days ago there was a 45% chance of a gove...</td>\n",
       "      <td>[Mark J. Perry]</td>\n",
       "      <td>August 17, 2009</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Carpe Diem]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.aei.org/research-products/working-...</td>\n",
       "      <td>Abstract\\nSince the 2009 Supervisory Capital A...</td>\n",
       "      <td>[Paul H. Kupiec]</td>\n",
       "      <td>April 2, 2019</td>\n",
       "      <td>[banking, financial stability]</td>\n",
       "      <td>[Economics]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.aei.org/carpe-diem/q-oil-speculato...</td>\n",
       "      <td>Last summer, Sen. Bernie Sanders (I-VT), a mem...</td>\n",
       "      <td>[Mark J. Perry]</td>\n",
       "      <td>October 27, 2014</td>\n",
       "      <td>[oil]</td>\n",
       "      <td>[Carpe Diem]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.aei.org/economics/october-jobs-rep...</td>\n",
       "      <td>The October jobs report contained lots of good...</td>\n",
       "      <td>[James Pethokoukis]</td>\n",
       "      <td>November 4, 2016</td>\n",
       "      <td>[jobs report, Labor force participation rate, ...</td>\n",
       "      <td>[Economics]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.aei.org/carpe-diem/map-of-the-gove...   \n",
       "1  https://www.aei.org/carpe-diem/from-45-to-15-i...   \n",
       "2  https://www.aei.org/research-products/working-...   \n",
       "3  https://www.aei.org/carpe-diem/q-oil-speculato...   \n",
       "5  https://www.aei.org/economics/october-jobs-rep...   \n",
       "\n",
       "                                                text               author  \\\n",
       "0  The map above from the Freedom Center of Misso...      [Mark J. Perry]   \n",
       "1   Ten days ago there was a 45% chance of a gove...      [Mark J. Perry]   \n",
       "2  Abstract\\nSince the 2009 Supervisory Capital A...     [Paul H. Kupiec]   \n",
       "3  Last summer, Sen. Bernie Sanders (I-VT), a mem...      [Mark J. Perry]   \n",
       "5  The October jobs report contained lots of good...  [James Pethokoukis]   \n",
       "\n",
       "               date                                                tag  \\\n",
       "0    August 6, 2011                                                 []   \n",
       "1   August 17, 2009                                                 []   \n",
       "2     April 2, 2019                     [banking, financial stability]   \n",
       "3  October 27, 2014                                              [oil]   \n",
       "5  November 4, 2016  [jobs report, Labor force participation rate, ...   \n",
       "\n",
       "        section  len  \n",
       "0  [Carpe Diem]    1  \n",
       "1  [Carpe Diem]    1  \n",
       "2   [Economics]    1  \n",
       "3  [Carpe Diem]    1  \n",
       "5   [Economics]    1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['url', 'text', 'author', 'date', 'tag', 'section']]\n",
    "data.to_csv('aei_text_8.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aei_text_1.csv\n",
      "aei_text_2.csv\n",
      "aei_text_3.csv\n",
      "aei_text_4.csv\n",
      "aei_text_5.csv\n",
      "aei_text_6.csv\n",
      "aei_text_7.csv\n",
      "aei_text_8.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 9):\n",
    "    file = f\"aei_text_{i}.csv\"\n",
    "    print(file)\n",
    "    data = data.append(pd.read_csv(file), sort=False)\n",
    "data.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [i.strip('[').strip(']').strip('\\'') if isinstance(i, str) else \"\" \n",
    "            for i in data[\"section\"]]\n",
    "data[\"section\"] = sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = data['date'].apply(lambda x: datetime.strptime(x, \n",
    "                                            '%B %d, %Y').strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [\", \".join(i.strip('[').strip(']').strip('\\'').split(\"', '\"))\n",
    "           for i in data[\"author\"]]\n",
    "data['author'] = authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values('date')\n",
    "data = data[['url', 'text', 'author', 'date', 'section']]\n",
    "data.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('aei_full_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
